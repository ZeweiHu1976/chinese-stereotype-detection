# RBT6 Full Dataset Prediction
# ä½¿ç”¨è®­ç»ƒå¥½çš„RBT6æ¨¡å‹å¯¹COLDå®Œæ•´æ•°æ®é›†è¿›è¡Œé¢„æµ‹
# è¾“å‡º: fullresult.csv

import pandas as pd
import numpy as np
import os
from pathlib import Path
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch
from tqdm import tqdm

# ==================== ç¯å¢ƒé…ç½® ====================
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# åŸºç¡€ç›®å½•é…ç½® - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
BASE_DIR = Path.cwd()

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    'model_dir': 'model_output_rbt6/rbt6_cold',  # è®­ç»ƒåä¿å­˜çš„RBT6æ¨¡å‹è·¯å¾„
    'model_name': 'RBT6'
}


def load_full_data(csv_file_path, labelling_criteria='stereotype'):
    """
    åŠ è½½å®Œæ•´æ•°æ®é›†ï¼ˆä¸åšåˆ’åˆ†ï¼‰
    
    Args:
        csv_file_path: CSVæ–‡ä»¶è·¯å¾„
        labelling_criteria: æ­£ç±»æ ‡ç­¾
    
    Returns:
        data: å®Œæ•´æ•°æ®é›†DataFrame
    """
    print(f"Loading full dataset from: {csv_file_path}")
    
    # è¯»å–æ•°æ®
    data = pd.read_csv(csv_file_path, usecols=['text', 'label', 'group'])
    print(f"Total data size: {len(data)}")
    
    # ä¿å­˜åŸå§‹æ ‡ç­¾
    data['original_label'] = data['label']
    
    # æ ‡ç­¾äºŒå€¼åŒ–
    label2id = {label: (1 if label == labelling_criteria else 0) for label in data['label'].unique()}
    data['label'] = data['label'].map(label2id)
    
    print(f"Label mapping: {label2id}")
    print(f"Label distribution:\n{data['label'].value_counts()}")
    
    return data


def predict_batch(model, tokenizer, texts, device, batch_size=32):
    """
    æ‰¹é‡é¢„æµ‹
    
    Args:
        model: åŠ è½½çš„æ¨¡å‹
        tokenizer: åˆ†è¯å™¨
        texts: æ–‡æœ¬åˆ—è¡¨
        device: è®¾å¤‡
        batch_size: æ‰¹æ¬¡å¤§å°
    
    Returns:
        predictions: é¢„æµ‹æ ‡ç­¾
        probabilities: é¢„æµ‹æ¦‚ç‡
    """
    model.eval()
    all_predictions = []
    all_probabilities = []
    
    num_batches = (len(texts) + batch_size - 1) // batch_size
    
    with torch.no_grad():
        for i in tqdm(range(num_batches), desc="Predicting"):
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size, len(texts))
            batch_texts = texts[start_idx:end_idx].tolist()
            
            # åˆ†è¯
            inputs = tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors='pt'
            )
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            # é¢„æµ‹
            outputs = model(**inputs)
            logits = outputs.logits
            
            # è®¡ç®—æ¦‚ç‡
            probs = torch.softmax(logits, dim=1)
            predictions = torch.argmax(logits, dim=1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_probabilities.extend(probs.cpu().numpy())
    
    return np.array(all_predictions), np.array(all_probabilities)


def main():
    # é…ç½®
    CONFIG = {
        'csv_file_path': BASE_DIR / 'cold.csv',  # æ•°æ®é›†è·¯å¾„ï¼Œè¯·æ ¹æ®å®é™…ä¿®æ”¹
        'labelling_criteria': 'stereotype',
        'batch_size': 32,
        'output_file': 'fullresult.csv'
    }
    
    print("="*70)
    print("RBT6 Full Dataset Prediction")
    print("="*70)
    
    # æ£€æµ‹è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if torch.cuda.is_available():
        print(f"ğŸš€ GPU detected: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  No GPU detected, using CPU")
    
    # 1. åŠ è½½å®Œæ•´æ•°æ®
    print("\n[Step 1/3] Loading full dataset...")
    data = load_full_data(
        csv_file_path=CONFIG['csv_file_path'],
        labelling_criteria=CONFIG['labelling_criteria']
    )
    
    # 2. åŠ è½½æ¨¡å‹
    print("\n[Step 2/3] Loading RBT6 model...")
    print(f"Model path: {MODEL_CONFIG['model_dir']}")
    
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_CONFIG['model_dir'])
    tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG['model_dir'])
    model.to(device)
    print("Model loaded successfully!")
    
    # 3. é¢„æµ‹
    print("\n[Step 3/3] Running predictions...")
    predictions, probabilities = predict_batch(
        model=model,
        tokenizer=tokenizer,
        texts=data['text'],
        device=device,
        batch_size=CONFIG['batch_size']
    )
    
    # 4. æ„å»ºç»“æœDataFrame
    print("\nBuilding result DataFrame...")
    
    result_df = data.copy()
    result_df['predicted_label'] = predictions
    result_df['prob_non_stereotype'] = probabilities[:, 0]  # ç±»åˆ«0çš„æ¦‚ç‡
    result_df['prob_stereotype'] = probabilities[:, 1]      # ç±»åˆ«1çš„æ¦‚ç‡
    result_df['correct'] = (result_df['predicted_label'] == result_df['label']).astype(int)
    
    # æ·»åŠ é¢„æµ‹æ ‡ç­¾çš„æ–‡å­—æè¿°
    result_df['predicted_label_text'] = result_df['predicted_label'].map({0: 'non-stereotype', 1: 'stereotype'})
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    result_df = result_df[[
        'text', 
        'group',
        'original_label',
        'label',
        'predicted_label',
        'predicted_label_text',
        'prob_non_stereotype',
        'prob_stereotype',
        'correct'
    ]]
    
    # 5. ä¿å­˜ç»“æœ
    output_path = CONFIG['output_file']
    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… Results saved to: {output_path}")
    
    # 6. æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*70)
    print("PREDICTION SUMMARY")
    print("="*70)
    
    total = len(result_df)
    correct = result_df['correct'].sum()
    accuracy = correct / total
    
    print(f"\nOverall Statistics:")
    print(f"  Total samples: {total}")
    print(f"  Correct predictions: {correct}")
    print(f"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    print(f"\nPrediction Distribution:")
    print(f"  Predicted as stereotype: {(result_df['predicted_label'] == 1).sum()}")
    print(f"  Predicted as non-stereotype: {(result_df['predicted_label'] == 0).sum()}")
    
    print(f"\nActual Distribution:")
    print(f"  Actual stereotype: {(result_df['label'] == 1).sum()}")
    print(f"  Actual non-stereotype: {(result_df['label'] == 0).sum()}")
    
    # æŒ‰groupç»Ÿè®¡
    print(f"\nAccuracy by Group:")
    group_stats = result_df.groupby('group').agg({
        'correct': ['sum', 'count', 'mean']
    }).round(4)
    group_stats.columns = ['Correct', 'Total', 'Accuracy']
    print(group_stats)
    
    # é”™è¯¯æ ·æœ¬åˆ†æ
    errors = result_df[result_df['correct'] == 0]
    print(f"\nError Analysis:")
    print(f"  Total errors: {len(errors)}")
    
    # False Positives (é¢„æµ‹ä¸ºstereotypeä½†å®é™…ä¸æ˜¯)
    fp = errors[errors['predicted_label'] == 1]
    print(f"  False Positives (predicted stereotype, actual non-stereotype): {len(fp)}")
    
    # False Negatives (é¢„æµ‹ä¸ºnon-stereotypeä½†å®é™…æ˜¯)
    fn = errors[errors['predicted_label'] == 0]
    print(f"  False Negatives (predicted non-stereotype, actual stereotype): {len(fn)}")
    
    print("\n" + "="*70)
    print("âœ… Full dataset prediction completed!")
    print("="*70)
    
    return result_df


if __name__ == "__main__":
    result_df = main()
